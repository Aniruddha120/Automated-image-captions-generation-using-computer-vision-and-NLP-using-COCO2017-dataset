{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "E8dVG88_uvns"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import re,os,time,json,pickle\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
        "                                          cache_subdir=os.path.abspath('.'),\n",
        "                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip',\n",
        "                                          extract = True)\n",
        "annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2017.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpTj7ROGv9t9",
        "outputId": "0baabf8d-9872-4373-b2c2-efb2827bcc0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "252907541/252907541 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_of_zip = 'train2017.zip'\n",
        "if not os.path.exists(os.path.abspath('.') + '/' + name_of_zip):\n",
        "  image_zip = tf.keras.utils.get_file(name_of_zip,\n",
        "  cache_subdir=os.path.abspath('.'),\n",
        "  origin = 'http://images.cocodataset.org/zips/train2017.zip',\n",
        "  extract = True)\n",
        "  PATH = os.path.dirname(image_zip)+'/train2017/'\n",
        "else:\n",
        "  PATH = os.path.abspath('.')+'/train2017/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xsiP526124_",
        "outputId": "d5736088-b8e6-49ac-e772-f6e814f96dd7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://images.cocodataset.org/zips/train2017.zip\n",
            "19336861798/19336861798 [==============================] - 323s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the json annotation file\n",
        "with open(annotation_file, 'r') as f:\n",
        "    annotations = json.load(f)"
      ],
      "metadata": {
        "id": "AWA2bgT953TJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# storing the captions and the image name in vectors\n",
        "all_captions = []\n",
        "all_img_name_vector = []\n",
        "\n",
        "for annot in annotations['annotations']:\n",
        "  caption = '<start> ' + annot['caption'] + ' <end>'\n",
        "  image_id = annot['image_id']\n",
        "  full_coco_image_path = PATH + 'COCO_train2014_' + '%012d.jpg' % (image_id)\n",
        "\n",
        "  all_img_name_vector.append(full_coco_image_path)\n",
        "  all_captions.append(caption)\n",
        "\n",
        "# shuffling the captions and image_names together\n",
        "# setting a random state\n",
        "train_captions, img_name_vector = shuffle(all_captions,\n",
        "all_img_name_vector,\n",
        "random_state=1)\n",
        "\n",
        "# selecting the first 40000 captions from the shuffled set\n",
        "num_examples = 40000\n",
        "train_captions = train_captions[:num_examples]\n",
        "img_name_vector = img_name_vector[:num_examples]"
      ],
      "metadata": {
        "id": "8AOeDM4I53PV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resizing the image to (299, 299)\n",
        "#Using the preprocess_input method to place the pixels in the range of -1 to 1.\n",
        "def load_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (299, 299))\n",
        "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "    return img, image_path"
      ],
      "metadata": {
        "id": "RwIZzrEt53Ny"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_model = tf.keras.applications.InceptionV3(include_top=False,\n",
        "                                                weights='imagenet')\n",
        "new_input = image_model.input\n",
        "hidden_layer = image_model.layers[-1].output"
      ],
      "metadata": {
        "id": "VKl1XscA53KL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode_train = sorted(set(img_name_vector))\n",
        "\n",
        "    # feel free to change the batch_size according to your system configuration\n",
        "image_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "                                encode_train).map(load_image).batch(16)\n",
        "for img, path in image_dataset:\n",
        "  batch_features = image_features_extract_model(img)\n",
        "  batch_features = tf.reshape(batch_features,\n",
        "                              (batch_features.shape[0], -1, batch_features.shape[3]))\n",
        "#Dump into disk\n",
        "  for bf, p in zip(batch_features, path):\n",
        "    path_of_feature = p.numpy().decode(\"utf-8\")\n",
        "    np.save(path_of_feature, bf.numpy())"
      ],
      "metadata": {
        "id": "XdZp6CWm53Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VLqGmWxf53GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s8XvdDve53Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fTqiXVbr53B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vR8WKTMH53AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b_jSsGJN529q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l8xEKQa1527w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}